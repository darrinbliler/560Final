---
title: "TBANLT 560 Project 2 Towards a Data Mining Portfolio"
author: "Darrin Bliler"
date: "3/17/2021"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = normalizePath("C:/Users/darri/OneDrive - UW/UWT MSBA/TBANLT 560"))
```

```{r}
#load the mlbench package which has the BreastCancer data set

require(mlbench)
```
#### Upload Data Set. Omit missing data.
```{r}
data(BreastCancer)
BreastCancer <- na.omit(BreastCancer) 
```


### Partition the data set for 80% training and 20% evaluation. The method used is recursive (or iterative) partitioning
```{r}
BreastCancer$Id <- NULL 
# partition the data set for 80% training and 20% evaluation (adapted from ?randomForest)
set.seed(2)

ind <- sample(2, nrow(BreastCancer), replace = TRUE, prob=c(0.8, 0.2))
# create model using recursive partitioning on the training data set
require(rpart)
x.rp <- rpart(Class ~ ., data=BreastCancer[ind == 1,])
# predict classes for the evaluation data set
x.rp.pred <- predict(x.rp, type="class", newdata=BreastCancer[ind == 2,])
# score the evaluation data set (extract the probabilities)
x.rp.prob <- predict(x.rp, type="prob", newdata=BreastCancer[ind == 2,])
plot(x.rp, main="Decision tree created using rpart")
```

### The above decision tree shows the probabilities of the evaluation dataset

### Next I will create a model using conditional inference trees

```{r}
# create model using conditional inference trees
require(party)
x.ct <- ctree(Class ~ ., data=BreastCancer[ind == 1,])
x.ct.pred <- predict(x.ct, newdata=BreastCancer[ind == 2,])
x.ct.prob <-  1- unlist(treeresponse(x.ct, BreastCancer[ind == 2,]), use.names=F)[seq(1,nrow(BreastCancer[ind == 2,])*2,2)]
```

### Next, we plot the Decision tree created using condition inference trees and bagging ensemble
```{r}
# To view the decision tree, uncomment this line.
plot(x.ct, main="Decision tree created using condition inference trees")

# create model using random forest and bagging ensemble using conditional inference trees
x.cf <- cforest(Class ~ ., data=BreastCancer[ind == 1,], control = cforest_unbiased(mtry = ncol(BreastCancer)-2))
x.cf.pred <- predict(x.cf, newdata=BreastCancer[ind == 2,])
x.cf.prob <-  1- unlist(treeresponse(x.cf, BreastCancer[ind == 2,]), use.names=F)[seq(1,nrow(BreastCancer[ind == 2,])*2,2)]

```

### Now I will experiment with bootstrap aggregating / bagging
```{r}
# create model using bagging (bootstrap aggregating)
require(ipred)
x.ip <- bagging(Class ~ ., data=BreastCancer[ind == 1,])
x.ip.prob <- predict(x.ip, type="prob", newdata=BreastCancer[ind == 2,])
```


### Next I will create my SVM model
```{r}
# create model using svm (support vector machine)
require(e1071)

# svm requires tuning
x.svm.tune <- tune(svm, Class~., data = BreastCancer[ind == 1,],
                   ranges = list(gamma = 2^(-8:1), cost = 2^(0:4)),
                   tunecontrol = tune.control(sampling = "fix"))
# display the tuning results (in text format)
x.svm.tune
# If the tuning results are on the margin of the parameters (e.g., gamma = 2^-8), 
# then widen the parameters.
# I manually copied the cost and gamma from console messages above to parameters below.
x.svm <- svm(Class~., data = BreastCancer[ind == 1,], cost=4, gamma=0.0625, probability = TRUE)
x.svm.prob <- predict(x.svm, type="prob", newdata=BreastCancer[ind == 2,], probability = TRUE)


##
## plot ROC curves to compare the performance of the individual classifiers
##

# Output the plot to a PNG file for display on web.  To draw to the screen, 
# comment this line out.
png(filename="roc_curve_5_models.png", width=700, height=700)

# load the ROCR package which draws the ROC curves
require(ROCR)
```

### The next block of code shows how to create an ROCR prediction object. The best part is being able to see the models' performance depicted in a chart. 
```{r}
x.rp.prob.rocr <- prediction(x.rp.prob[,2], BreastCancer[ind == 2,'Class'])
# prepare an ROCR performance object for ROC curve (tpr=true positive rate, fpr=false positive rate)
x.rp.perf <- performance(x.rp.prob.rocr, "tpr","fpr")
# plot it
plot(x.rp.perf, col=2, main="ROC curves comparing classification performance of five machine learning models")

# Draw a legend.
legend(0.6, 0.6, c('rpart', 'ctree', 'cforest','bagging','svm'), 2:6)

# ctree
x.ct.prob.rocr <- prediction(x.ct.prob, BreastCancer[ind == 2,'Class'])
x.ct.perf <- performance(x.ct.prob.rocr, "tpr","fpr")
# add=TRUE draws on the existing chart 
plot(x.ct.perf, col=3, add=TRUE)


# cforest
x.cf.prob.rocr <- prediction(x.cf.prob, BreastCancer[ind == 2,'Class'])
x.cf.perf <- performance(x.cf.prob.rocr, "tpr","fpr")
plot(x.cf.perf, col=4, add=TRUE)

# bagging
x.ip.prob.rocr <- prediction(x.ip.prob[,2], BreastCancer[ind == 2,'Class'])
x.ip.perf <- performance(x.ip.prob.rocr, "tpr","fpr")
plot.new()
plot(x.ip.perf, col=5, add=TRUE)
# svm
x.svm.prob.rocr <- prediction(attr(x.svm.prob, "probabilities")[,2], BreastCancer[ind == 2,'Class'])
x.svm.perf <- performance(x.svm.prob.rocr, "tpr","fpr")

plot(x.svm.perf, col=6, add=TRUE)

# Close and save the PNG file.
dev.off()

```
### I'm starting my analysis with the Breast Cancer set again and choosing to only utilize rows / records with all the data.
```{r}
data("BreastCancer")
#import only complete cases
BreastCancer <- BreastCancer[complete.cases(BreastCancer), ]
mydata <- cbind(BreastCancer[10],BreastCancer[1:9])

mysvm <- svm(BreastCancer$Class ~ ., BreastCancer)
mysvm.pred <- predict(mysvm, BreastCancer)
table(mysvm.pred,BreastCancer$Class)
```
### Next I will use the Naive Bayes model to predict Class.

```{r}
library(klaR)
mynb <- NaiveBayes(Class ~ ., BreastCancer)

mynb.pred <- predict(mynb,BreastCancer)
```
### This table shows the confusion matrix for benign and malignant

```{r}
table(mynb.pred$class,BreastCancer$Class)
```
### This block of code shows the weights of the neural net and assists in grouping data.

```{r}
library(nnet)
mynnet <- nnet(Class ~ ., BreastCancer, size=1)
mynnet.pred <- predict(mynnet,BreastCancer,type="class")
table(mynnet.pred,BreastCancer$Class)
```

### Next is the Decision Tree model. I iterated and experimented with the tree.

```{r}
mytree <- rpart(Class ~ Cell.size+Cell.shape+Marg.adhesion+Cl.thickness+Mitoses+Bl.cromatin+Mitoses,BreastCancer)
```


```{r}
plot(mytree); text(mytree)
summary(mytree)
mytree.pred <- predict(mytree,BreastCancer,type="class")
table(mytree.pred,BreastCancer$Class)
```

### Breast Cancer subset of variables and a loop to generate the confusion matrix
```{r}
BreastCancer <- subset(BreastCancer, select = -c(1))

ans <- numeric(length(BreastCancer[,1]))
for (i in 1:length(BreastCancer[,1])) {
  mytree <- rpart(Class ~ ., BreastCancer[-i,])
  mytree.pred <- predict(mytree,BreastCancer[i,],type="class")
  ans[i] <- mytree.pred}

ans <- factor(ans,labels=levels(BreastCancer$Class))
table(ans,BreastCancer$Class)
```

```{r}
library(MASS)
BreastCancer$Cl.thickness <- as.numeric(BreastCancer$Cl.thickness)
BreastCancer$Bare.nuclei <- as.numeric(BreastCancer$Bare.nuclei)
BreastCancer$Bl.cromatin <- as.numeric(BreastCancer$Bl.cromatin)
BreastCancer$Normal.nucleoli <- as.numeric(BreastCancer$Normal.nucleoli)
BreastCancer$Cell.size <- as.numeric(BreastCancer$Cell.size)
BreastCancer$Cell.shape <- as.numeric(BreastCancer$Cell.shape)
BreastCancer$Marg.adhesion <- as.numeric(BreastCancer$Marg.adhesion)
BreastCancer$Epith.c.size <- as.numeric(BreastCancer$Epith.c.size)
BreastCancer$Mitoses <- as.numeric(BreastCancer$Mitoses)
BreastCancer$Class <- as.factor(BreastCancer$Class)
str(BreastCancer)
summary(BreastCancer)
myqda <- qda(Class ~ ., BreastCancer)
myqda.pred <- predict(myqda, BreastCancer)
table(myqda.pred$class,BreastCancer$Class)
```


```{r}
library(randomForest)
myrf <- randomForest(Class ~ .,BreastCancer)
myrf.pred <- predict(myrf, BreastCancer)
table(myrf.pred, BreastCancer$Class)
```

```{r}
library(klaR)
myrda <- rda(Class ~ ., BreastCancer)
myrda.pred <- predict(myrda, BreastCancer)
table(myrda.pred$class,BreastCancer$Class)
```


### Now it's time to combine the output from the different models using Majority rule ensemble approach.

```{r}
library(MASS)
combine.classes<-data.frame(myrf.pred, myrda.pred$class,#myqda.pred,
mytree.pred,mynnet.pred,mysvm.pred, mynb.pred$class)
head(combine.classes)
head(myrf.pred)
head(myrda.pred)
combine.classes$myrf.pred<-ifelse(combine.classes$myrf.pred=="benign", 0, 1)
combine.classes[,2]<-ifelse(combine.classes[,2]=="benign", 0, 1)
combine.classes[,3]<-ifelse(combine.classes[,3]=="benign", 0, 1)
combine.classes[,4]<-ifelse(combine.classes[,4]=="benign", 0, 1)
combine.classes[,5]<-ifelse(combine.classes[,5]=="benign", 0, 1)
combine.classes[,6]<-ifelse(combine.classes[,6]=="benign", 0, 1)
majority.vote=rowSums(combine.classes)
head(majority.vote)
combine.classes[,7]<-rowSums(combine.classes)
combine.classes[,8]<-ifelse(combine.classes[,7]>=4, "malignant", "benign")
table(combine.classes[,8], BreastCancer$Class)
```



